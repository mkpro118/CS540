{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a870a62-4796-44b9-9a1a-5165c59f048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Any, Self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "831a995b-7b72-4be1-b1ef-299d45f8c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write(file: str, data: Any):\n",
    "    with open(file, 'w') as f:\n",
    "        f.write(data if isinstance(data, str) else str(data))\n",
    "\n",
    "def rescale(x: np.ndarray) -> np.ndarray:\n",
    "    min_ = np.min(x)\n",
    "    range_ = np.ptp(x)\n",
    "    return (x - min_) / range_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b718a53-3fb8-4a5a-86df-f4e1088fe9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('time_series_covid19_deaths_US_raw.csv')\n",
    "raw_data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1a133db-017a-4d05-ad5d-7a5dfdea9906",
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_data = np.cumsum(raw_data, axis=0)\n",
    "data = np.diff(cum_data)\n",
    "\n",
    "del raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c78a7e1-ca01-4372-a964-71e0e43853a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wisc_cal_data = cum_data[(4, 48), :]\n",
    "# q1_str = '\\n'.join((','.join(map(str, x)) for x in wisc_cal_data.tolist()))\n",
    "# write('q1.txt', q1_str)\n",
    "\n",
    "# del cum_data\n",
    "# del q1_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0776207-950f-405a-97e1-61be003f86d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q2_data = data[(4, 48), :] # 4-> cal, 48 -> wisco\n",
    "# q2_str = '\\n'.join((','.join(map(str, x)) for x in q2_data.tolist()))\n",
    "# write('q2.txt', q2_str)\n",
    "\n",
    "# del q2_data\n",
    "# del q2_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57e5307f-105e-41b8-926b-1598e787149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write('q3.txt', '''Mean of the time-differenced data\n",
    "# Standard deviation of the time-differenced data\n",
    "# Median of the time-differenced data\n",
    "# Linear trend coefficient of the data\n",
    "# Auto-correlation of the data''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbf249da-68f6-43ea-aa31-9b87aae921de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(data, axis=1)\n",
    "mean = rescale(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eef45d3-b077-4671-b23c-c37f3deedd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.std(data, axis=1)\n",
    "std = rescale(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be3427de-0d2f-4723-8c6a-8edb51e2db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "median = np.median(data, axis=1)\n",
    "median = rescale(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b596765-6524-4eca-8a2f-b4aa12303de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltc = np.array([sum((x[i] - mean[idx]) * (i + 1 - (half_length := ((data.shape[-1] + 1) / 2))) for i in range(len(x))) for idx, x in enumerate(data.tolist())]) / sum((i+1 - half_length) ** 2 for i in range(data.shape[-1]))\n",
    "ltc = rescale(ltc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b14d1ecb-1370-4401-8602-6e57de68e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = np.array([ sum((x[i] * x[i-1] for i in range(1, len(x)))) / np.sum(np.power(x, 2)) for x in (data - mean.reshape(50, -1)).tolist()])\n",
    "ac = rescale(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98593ab8-e689-499d-9236-331944c16b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parametric_data = np.empty((50, 5))\n",
    "parametric_data[:, 0] = mean\n",
    "parametric_data[:, 1] = std\n",
    "parametric_data[:, 2] = median\n",
    "parametric_data[:, 3] = ltc\n",
    "parametric_data[:, 4] = ac\n",
    "\n",
    "# q4_str = '\\n'.join((','.join(map(lambda s: f'{s:.4f}', x)) for x in np.around(parametric_data, 4).tolist()))\n",
    "# write('q4.txt', q4_str)\n",
    "# del q4_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd919c80-3ece-4075-88de-8333eb53a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalClustering:\n",
    "    class Clustering:\n",
    "        @staticmethod\n",
    "        def _compute_distances(X: np.ndarray) -> np.ndarray:\n",
    "            n = X.shape[0]\n",
    "            distance_matrix = np.zeros((n, n))\n",
    "        \n",
    "            for i in range(n):\n",
    "                for j in range(i + 1, n):\n",
    "                    distance_matrix[i, j] = np.linalg.norm(X[i] - X[j])\n",
    "        \n",
    "            distance_matrix += distance_matrix.T\n",
    "        \n",
    "            return distance_matrix\n",
    "        \n",
    "        @staticmethod\n",
    "        def _single(distance_matrix: np.ndarray, num_clusters: int) -> list:\n",
    "            num_points = distance_matrix.shape[0]\n",
    "            clusters = [[i] for i in range(num_points)]\n",
    "        \n",
    "            while len(clusters) > num_clusters:\n",
    "                # Find the two closest clusters\n",
    "                min_distance = np.inf\n",
    "                merge_index1, merge_index2 = None, None\n",
    "        \n",
    "                for i in range(len(clusters)):\n",
    "                    for j in range(i + 1, len(clusters)):\n",
    "                        cluster1 = clusters[i]\n",
    "                        cluster2 = clusters[j]\n",
    "        \n",
    "                        # Find the minimum distance between the two clusters\n",
    "                        distance = np.min(distance_matrix[np.ix_(cluster1, cluster2)])\n",
    "        \n",
    "                        if distance < min_distance:\n",
    "                            min_distance = distance\n",
    "                            merge_index1, merge_index2 = i, j\n",
    "        \n",
    "                # Merge the two closest clusters\n",
    "                clusters[merge_index1].extend(clusters[merge_index2])\n",
    "                del clusters[merge_index2]\n",
    "        \n",
    "                # Update the distance matrix with the new distances from the merged cluster\n",
    "                combined_cluster = clusters[merge_index1]\n",
    "                for i in range(distance_matrix.shape[0]):\n",
    "                    if i in combined_cluster:\n",
    "                        continue\n",
    "                    distance = np.min(distance_matrix[np.ix_(combined_cluster, [i])])\n",
    "                    distance_matrix[i, combined_cluster] = distance\n",
    "                    distance_matrix[combined_cluster, i] = distance\n",
    "        \n",
    "            return tuple(map(tuple, clusters))\n",
    "    \n",
    "        @staticmethod\n",
    "        def _complete(distance_matrix: np.ndarray, n_clusters: int) -> list:\n",
    "            num_points = distance_matrix.shape[0]\n",
    "            clusters = [[i] for i in range(num_points)]\n",
    "        \n",
    "            while len(clusters) > n_clusters:\n",
    "                # Find the two clusters with the smallest maximum distance\n",
    "                min_max_distance = np.inf\n",
    "                merge_index1, merge_index2 = None, None\n",
    "        \n",
    "                for i in range(len(clusters)):\n",
    "                    for j in range(i + 1, len(clusters)):\n",
    "                        cluster1 = clusters[i]\n",
    "                        cluster2 = clusters[j]\n",
    "        \n",
    "                        # Find the maximum distance between the two clusters\n",
    "                        max_distance = np.max(distance_matrix[np.ix_(cluster1, cluster2)])\n",
    "        \n",
    "                        if max_distance < min_max_distance:\n",
    "                            min_max_distance = max_distance\n",
    "                            merge_index1, merge_index2 = i, j\n",
    "        \n",
    "                # Merge the two closest clusters\n",
    "                clusters[merge_index1].extend(clusters[merge_index2])\n",
    "                del clusters[merge_index2]\n",
    "        \n",
    "                # Update the distance matrix with the new distances from the merged cluster\n",
    "                combined_cluster = clusters[merge_index1]\n",
    "                for i in range(distance_matrix.shape[0]):\n",
    "                    if i in combined_cluster:\n",
    "                        continue\n",
    "                    distance = np.max(distance_matrix[np.ix_(combined_cluster, [i])])\n",
    "                    distance_matrix[i, combined_cluster] = distance\n",
    "                    distance_matrix[combined_cluster, i] = distance\n",
    "        \n",
    "            return clusters\n",
    "        \n",
    "    _METHODS = {\n",
    "        'single': Clustering._single,\n",
    "        'complete': Clustering._complete,\n",
    "    }\n",
    "\n",
    "    def __init__(self, n_clusters: int = 2, linkage: str = 'single'):\n",
    "        self._n_clusters = n_clusters\n",
    "        \n",
    "        assert HierarchicalClustering._is_linkage_valid(linkage), (\n",
    "            f'Invalid Linkage, valid linkages are \\'single\\' and '\n",
    "            f'\\'complete\\', found {linkage!r}'\n",
    "        )\n",
    "        \n",
    "        self._linkage = linkage\n",
    "\n",
    "    def _build(self, X: np.ndarray):\n",
    "        distance_matrix = HierarchicalClustering.Clustering._compute_distances(X)\n",
    "        cluster_func = HierarchicalClustering._METHODS.get(self._linkage)\n",
    "        if cluster_func is None:\n",
    "            raise ValueError(\n",
    "                f'Invalid Linkage, the Hierarchical Clustering instance '\n",
    "                f'may have been tampered with. found {self.linkage!r}'\n",
    "            )\n",
    "\n",
    "        self._clusters = cluster_func(distance_matrix, self._n_clusters)\n",
    "\n",
    "    def fit(self, X: np.ndarray) -> Self:\n",
    "        self._build(X)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: np.ndarray):\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    def clusters(self):\n",
    "        return self._clusters\n",
    "\n",
    "    @clusters.setter\n",
    "    def clusters(self, value):\n",
    "        raise ValueError('The `clusters` attribute should not be modified externally!')\n",
    "    \n",
    "    @staticmethod\n",
    "    def _is_linkage_valid(linkage: str) -> bool:\n",
    "        return linkage in HierarchicalClustering._METHODS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "990d2115-78bb-472f-8494-7c100e1b0cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "slhc = HierarchicalClustering(n_clusters = 5)\n",
    "slhc = slhc.fit(parametric_data)\n",
    "\n",
    "idxs = np.arange(parametric_data.shape[0])\n",
    "\n",
    "for cluster_idx, cluster in enumerate(slhc.clusters):\n",
    "    for item in cluster:\n",
    "        idxs[item] = cluster_idx\n",
    "\n",
    "# q5_str = ', '.join(map(str, idxs.tolist()))\n",
    "# write('q5.txt', q5_str)\n",
    "# del q5_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1464e1fd-b763-4c1d-9d6f-97ad3f59af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "clhc = HierarchicalClustering(n_clusters = 5, linkage='complete')\n",
    "clhc = clhc.fit(parametric_data)\n",
    "\n",
    "idxs = np.arange(parametric_data.shape[0])\n",
    "\n",
    "for cluster_idx, cluster in enumerate(clhc.clusters):\n",
    "    for item in cluster:\n",
    "        idxs[item] = cluster_idx\n",
    "\n",
    "# q6_str = ', '.join(map(str, idxs.tolist()))\n",
    "# write('q6.txt', q6_str)\n",
    "# del q6_str"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
