{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a870a62-4796-44b9-9a1a-5165c59f048f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import Any\n",
    "try:\n",
    "    from typing import Self\n",
    "except ImportError:\n",
    "    from typing_extensions import Self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "831a995b-7b72-4be1-b1ef-299d45f8c540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_str(arr):\n",
    "    if arr.ndim == 1:\n",
    "        return ','.join(map(str, np.around(arr, 4).tolist()))\n",
    "    elif arr.ndim == 2:\n",
    "        return '\\n'.join((','.join(map(str, x)) for x in np.around(arr, 4).tolist()))\n",
    "    else:\n",
    "        raise ValueError('Only 1 and 2-d arrays suppported')\n",
    "\n",
    "def write(file: str, data: Any):\n",
    "    with open(file, 'w') as f:\n",
    "        f.write(data if isinstance(data, str) else str(data))\n",
    "\n",
    "def rescale(x: np.ndarray) -> np.ndarray:\n",
    "    min_ = np.min(x)\n",
    "    range_ = np.ptp(x)\n",
    "    return (x - min_) / range_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b718a53-3fb8-4a5a-86df-f4e1088fe9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('time_series_covid19_deaths_US_raw.csv')\n",
    "raw_data = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1a133db-017a-4d05-ad5d-7a5dfdea9906",
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_data = np.cumsum(raw_data, axis=0)\n",
    "data = np.diff(cum_data)\n",
    "\n",
    "del raw_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c78a7e1-ca01-4372-a964-71e0e43853a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wisc_cal_data = cum_data[(4, 48), :]\n",
    "# q1_str = array_to_str(wisc_cal_data)\n",
    "# write('q1.txt', q1_str)\n",
    "\n",
    "# del cum_data\n",
    "# del q1_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0776207-950f-405a-97e1-61be003f86d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q2_data = data[(4, 48), :] # 4-> cal, 48 -> wisco\n",
    "# q2_str = array_to_str(q2_data)\n",
    "# write('q2.txt', q2_str)\n",
    "\n",
    "# del q2_data\n",
    "# del q2_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57e5307f-105e-41b8-926b-1598e787149c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write('q3.txt', '''Mean of the time-differenced data\n",
    "# Standard deviation of the time-differenced data\n",
    "# Median of the time-differenced data\n",
    "# Linear trend coefficient of the data\n",
    "# Auto-correlation of the data''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbf249da-68f6-43ea-aa31-9b87aae921de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(data, axis=1)\n",
    "mean = rescale(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8eef45d3-b077-4671-b23c-c37f3deedd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.std(data, axis=1)\n",
    "std = rescale(std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be3427de-0d2f-4723-8c6a-8edb51e2db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "median = np.median(data, axis=1)\n",
    "median = rescale(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b596765-6524-4eca-8a2f-b4aa12303de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltc = np.array([sum((x[i] - mean[idx]) * (i + 1 - (half_length := ((data.shape[-1] + 1) / 2))) for i in range(len(x))) for idx, x in enumerate(data.tolist())]) / sum((i+1 - half_length) ** 2 for i in range(data.shape[-1]))\n",
    "ltc = rescale(ltc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b14d1ecb-1370-4401-8602-6e57de68e0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ac = np.array([ sum((x[i] * x[i-1] for i in range(1, len(x)))) / np.sum(np.power(x, 2)) for x in (data - mean.reshape(50, -1)).tolist()])\n",
    "ac = rescale(ac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98593ab8-e689-499d-9236-331944c16b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parametric_data = np.empty((50, 5))\n",
    "parametric_data[:, 0] = mean\n",
    "parametric_data[:, 1] = std\n",
    "parametric_data[:, 2] = median\n",
    "parametric_data[:, 3] = ltc\n",
    "parametric_data[:, 4] = ac\n",
    "\n",
    "# q4_str = array_to_str(parametric_data)\n",
    "# write('q4.txt', q4_str)\n",
    "# del q4_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd919c80-3ece-4075-88de-8333eb53a585",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalClustering:\n",
    "    class Clustering:\n",
    "        @staticmethod\n",
    "        def _compute_distances(X: np.ndarray) -> np.ndarray:\n",
    "            n = X.shape[0]\n",
    "            distance_matrix = np.zeros((n, n))\n",
    "        \n",
    "            for i in range(n):\n",
    "                for j in range(i + 1, n):\n",
    "                    distance_matrix[i, j] = np.linalg.norm(X[i] - X[j])\n",
    "        \n",
    "            distance_matrix += distance_matrix.T\n",
    "        \n",
    "            return distance_matrix\n",
    "        \n",
    "        @staticmethod\n",
    "        def _single(distance_matrix: np.ndarray, num_clusters: int) -> list:\n",
    "            num_points = distance_matrix.shape[0]\n",
    "            clusters = [[i] for i in range(num_points)]\n",
    "        \n",
    "            while len(clusters) > num_clusters:\n",
    "                # Find the two closest clusters\n",
    "                min_distance = np.inf\n",
    "                merge_index1, merge_index2 = None, None\n",
    "        \n",
    "                for i in range(len(clusters)):\n",
    "                    for j in range(i + 1, len(clusters)):\n",
    "                        cluster1 = clusters[i]\n",
    "                        cluster2 = clusters[j]\n",
    "        \n",
    "                        # Find the minimum distance between the two clusters\n",
    "                        distance = np.min(distance_matrix[np.ix_(cluster1, cluster2)])\n",
    "        \n",
    "                        if distance < min_distance:\n",
    "                            min_distance = distance\n",
    "                            merge_index1, merge_index2 = i, j\n",
    "        \n",
    "                # Merge the two closest clusters\n",
    "                clusters[merge_index1].extend(clusters[merge_index2])\n",
    "                del clusters[merge_index2]\n",
    "        \n",
    "                # Update the distance matrix with the new distances from the merged cluster\n",
    "                combined_cluster = clusters[merge_index1]\n",
    "                for i in range(distance_matrix.shape[0]):\n",
    "                    if i in combined_cluster:\n",
    "                        continue\n",
    "                    distance = np.min(distance_matrix[np.ix_(combined_cluster, [i])])\n",
    "                    distance_matrix[i, combined_cluster] = distance\n",
    "                    distance_matrix[combined_cluster, i] = distance\n",
    "        \n",
    "            return tuple(map(tuple, clusters))\n",
    "    \n",
    "        @staticmethod\n",
    "        def _complete(distance_matrix: np.ndarray, n_clusters: int) -> list:\n",
    "            num_points = distance_matrix.shape[0]\n",
    "            clusters = [[i] for i in range(num_points)]\n",
    "        \n",
    "            while len(clusters) > n_clusters:\n",
    "                # Find the two clusters with the smallest maximum distance\n",
    "                min_max_distance = np.inf\n",
    "                merge_index1, merge_index2 = None, None\n",
    "        \n",
    "                for i in range(len(clusters)):\n",
    "                    for j in range(i + 1, len(clusters)):\n",
    "                        cluster1 = clusters[i]\n",
    "                        cluster2 = clusters[j]\n",
    "        \n",
    "                        # Find the maximum distance between the two clusters\n",
    "                        max_distance = np.max(distance_matrix[np.ix_(cluster1, cluster2)])\n",
    "        \n",
    "                        if max_distance < min_max_distance:\n",
    "                            min_max_distance = max_distance\n",
    "                            merge_index1, merge_index2 = i, j\n",
    "        \n",
    "                # Merge the two closest clusters\n",
    "                clusters[merge_index1].extend(clusters[merge_index2])\n",
    "                del clusters[merge_index2]\n",
    "        \n",
    "                # Update the distance matrix with the new distances from the merged cluster\n",
    "                combined_cluster = clusters[merge_index1]\n",
    "                for i in range(distance_matrix.shape[0]):\n",
    "                    if i in combined_cluster:\n",
    "                        continue\n",
    "                    distance = np.max(distance_matrix[np.ix_(combined_cluster, [i])])\n",
    "                    distance_matrix[i, combined_cluster] = distance\n",
    "                    distance_matrix[combined_cluster, i] = distance\n",
    "        \n",
    "            return clusters\n",
    "        \n",
    "    _METHODS = {\n",
    "        'single': Clustering._single,\n",
    "        'complete': Clustering._complete,\n",
    "    }\n",
    "\n",
    "    def __init__(self, n_clusters: int = 2, linkage: str = 'single'):\n",
    "        self._n_clusters = n_clusters\n",
    "        \n",
    "        assert HierarchicalClustering._is_linkage_valid(linkage), (\n",
    "            f'Invalid Linkage, valid linkages are \\'single\\' and '\n",
    "            f'\\'complete\\', found {linkage!r}'\n",
    "        )\n",
    "        \n",
    "        self._linkage = linkage\n",
    "\n",
    "    def _build(self, X: np.ndarray):\n",
    "        distance_matrix = HierarchicalClustering.Clustering._compute_distances(X)\n",
    "        cluster_func = HierarchicalClustering._METHODS.get(self._linkage)\n",
    "        if cluster_func is None:\n",
    "            raise ValueError(\n",
    "                f'Invalid Linkage, the Hierarchical Clustering instance '\n",
    "                f'may have been tampered with. found {self.linkage!r}'\n",
    "            )\n",
    "\n",
    "        self._clusters = cluster_func(distance_matrix, self._n_clusters)\n",
    "\n",
    "    def fit(self, X: np.ndarray) -> Self:\n",
    "        self._build(X)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X: np.ndarray):\n",
    "        pass\n",
    "    \n",
    "    @property\n",
    "    def clusters(self):\n",
    "        return self._clusters\n",
    "\n",
    "    @clusters.setter\n",
    "    def clusters(self, value):\n",
    "        raise ValueError('The `clusters` attribute should not be modified externally!')\n",
    "    \n",
    "    @staticmethod\n",
    "    def _is_linkage_valid(linkage: str) -> bool:\n",
    "        return linkage in HierarchicalClustering._METHODS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "990d2115-78bb-472f-8494-7c100e1b0cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "slhc = HierarchicalClustering(n_clusters = 5)\n",
    "slhc = slhc.fit(parametric_data)\n",
    "\n",
    "idxs = np.arange(parametric_data.shape[0])\n",
    "\n",
    "for cluster_idx, cluster in enumerate(slhc.clusters):\n",
    "    for item in cluster:\n",
    "        idxs[item] = cluster_idx\n",
    "\n",
    "# q5_str = array_to_str(idxs)\n",
    "# write('q5.txt', q5_str)\n",
    "# del q5_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1464e1fd-b763-4c1d-9d6f-97ad3f59af67",
   "metadata": {},
   "outputs": [],
   "source": [
    "clhc = HierarchicalClustering(n_clusters = 5, linkage='complete')\n",
    "clhc = clhc.fit(parametric_data)\n",
    "\n",
    "idxs = np.arange(parametric_data.shape[0])\n",
    "\n",
    "for cluster_idx, cluster in enumerate(clhc.clusters):\n",
    "    for item in cluster:\n",
    "        idxs[item] = cluster_idx\n",
    "\n",
    "# q6_str = array_to_str(idxs)\n",
    "# write('q6.txt', q6_str)\n",
    "# del q6_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2871dc4a-5cb5-47b8-932d-8784807e81e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b[0]:\n",
      "[30 31 32 33 34]\n",
      "\n",
      "a - b[0]:\n",
      "[[-30 -30 -30 -30 -30]\n",
      " [-25 -25 -25 -25 -25]\n",
      " [-20 -20 -20 -20 -20]\n",
      " [-15 -15 -15 -15 -15]\n",
      " [-10 -10 -10 -10 -10]\n",
      " [ -5  -5  -5  -5  -5]\n",
      " [  0   0   0   0   0]\n",
      " [  5   5   5   5   5]\n",
      " [ 10  10  10  10  10]\n",
      " [ 15  15  15  15  15]]\n",
      "\n",
      "(a - b[0]) ** 2:\n",
      "[[900 900 900 900 900]\n",
      " [625 625 625 625 625]\n",
      " [400 400 400 400 400]\n",
      " [225 225 225 225 225]\n",
      " [100 100 100 100 100]\n",
      " [ 25  25  25  25  25]\n",
      " [  0   0   0   0   0]\n",
      " [ 25  25  25  25  25]\n",
      " [100 100 100 100 100]\n",
      " [225 225 225 225 225]]\n",
      "\n",
      "np.sum((a - b[0]) ** 2, axis=1):\n",
      "[4500 3125 2000 1125  500  125    0  125  500 1125]\n",
      "\n",
      "[30 31 32 33 34] 0\n",
      "[25 26 27 28 29] 1\n",
      "\n",
      "distances:\n",
      "[[4500. 3125.]\n",
      " [3125. 2000.]\n",
      " [2000. 1125.]\n",
      " [1125.  500.]\n",
      " [ 500.  125.]\n",
      " [ 125.    0.]\n",
      " [   0.  125.]\n",
      " [ 125.  500.]\n",
      " [ 500. 1125.]\n",
      " [1125. 2000.]]\n",
      "\n",
      "np.argmin(distances, axis=1):\n",
      "[1 1 1 1 1 1 0 0 0 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(50).reshape((-1, 5))\n",
    "\n",
    "b = np.random.default_rng().choice(\n",
    "    a,\n",
    "    size=2,\n",
    "    replace=False,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "distances = np.empty((a.shape[0], b.shape[0]))\n",
    "print('b[0]:', b[0], sep='\\n', end='\\n\\n')\n",
    "print('a - b[0]:', a - b[0], sep='\\n', end='\\n\\n')\n",
    "print('(a - b[0]) ** 2:', (a - b[0]) ** 2, sep='\\n', end='\\n\\n')\n",
    "print('np.sum((a - b[0]) ** 2, axis=1):', np.sum((a - b[0]) ** 2, axis=1), sep='\\n', end='\\n\\n')\n",
    "\n",
    "for i, _b in enumerate(b):\n",
    "    print(_b, i)\n",
    "    distances[:, i] = np.sum((a - _b) ** 2, axis=1)\n",
    "print()\n",
    "print('distances:', distances, sep='\\n', end='\\n\\n')\n",
    "print('np.argmin(distances, axis=1):', np.argmin(distances, axis=1), sep='\\n', end='\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4774cf37-17e2-425a-ad9e-cf364b24a2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    class Clustering:\n",
    "        @staticmethod\n",
    "        def assign_points(centroids: np.ndarray, X: np.ndarray) -> np.ndarray:\n",
    "            distance_matrix = KMeans.Clustering.compute_distances(centroids, X)\n",
    "            return np.argmin(distance_matrix, axis=1)\n",
    "        \n",
    "        @staticmethod\n",
    "        def choose_centroids(X: np.ndarray, k: int = 2) -> np.ndarray:\n",
    "            return np.random.default_rng().choice(\n",
    "                X,\n",
    "                size=k,\n",
    "                replace=False,\n",
    "                shuffle=False\n",
    "            )\n",
    "\n",
    "        @staticmethod\n",
    "        def compute_centroids(X: np.ndarray, assignments: np.ndarray, k: int) -> np.ndarray:\n",
    "            classes = np.unique(assignments)\n",
    "            \n",
    "            centroids = np.empty((max(k, classes.shape[0]), X.shape[1]))\n",
    "            \n",
    "            for i, class_ in enumerate(classes):\n",
    "                idxs = assignments == class_\n",
    "                centroids[i] = np.mean(X[idxs], axis=0)\n",
    "            \n",
    "            return centroids\n",
    "        \n",
    "        @staticmethod\n",
    "        def compute_distances(centroids: np.ndarray, X: np.ndarray) -> np.ndarray:\n",
    "            distances = np.empty((X.shape[0], centroids.shape[0]))\n",
    "            for i, c in enumerate(centroids):\n",
    "                distances[:, i] = np.sum((X - c) ** 2, axis=1)\n",
    "            \n",
    "            return distances\n",
    "    \n",
    "    def __init__(self, k: int = 2, max_iters: int = 100, delta: float = 1e-5, ):\n",
    "        self._k = k\n",
    "        self._max_iters = max_iters\n",
    "        self._delta = abs(delta)\n",
    "    \n",
    "    def _build(self, X: np.ndarray):\n",
    "        ctr = 0\n",
    "        intial_centroids = KMeans.Clustering.choose_centroids(X, self.k)\n",
    "        \n",
    "        while ctr < self._max_iters:  # avoid taking too much time\n",
    "            ctr += 1\n",
    "        \n",
    "            assignment = KMeans.Clustering.assign_points(intial_centroids, X)\n",
    "            updated_centroids = KMeans.Clustering.compute_centroids(X, assignment, self._k)\n",
    "            \n",
    "            if np.all(np.isclose(intial_centroids, updated_centroids)):\n",
    "                break\n",
    "            \n",
    "            if np.all(np.abs(updated_centroids - intial_centroids) < self._delta):\n",
    "                break\n",
    "            \n",
    "            initial_centroids = updated_centroids\n",
    "        \n",
    "        self._centroids = updated_centroids\n",
    "    \n",
    "    def fit(self, X: np.ndarray) -> Self:\n",
    "        self._build(X)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        return KMeans.Clustering.assign_points(self._centroids, X)\n",
    "    \n",
    "    @property\n",
    "    def centroids(self):\n",
    "        return self._centroids\n",
    "    \n",
    "    @centroids.setter\n",
    "    def centroids(self):\n",
    "        raise ValueError('The `centroids` attribute should not be modified externally!')\n",
    "    \n",
    "    @property\n",
    "    def k(self):\n",
    "        return self._k\n",
    "    \n",
    "    @k.setter\n",
    "    def k(self):\n",
    "        raise ValueError('The `k` attribute should not be modified externally!')\n",
    "    \n",
    "    def distortion(self, X: np.ndarray) -> np.ndarray:\n",
    "        _distortion = 0\n",
    "        \n",
    "        assignments = self.predict(X)\n",
    "        \n",
    "        classes = np.unique(assignments)\n",
    "        \n",
    "        for class_ in classes:\n",
    "            idxs = assignments == class_\n",
    "            _distortion += np.sum((X[idxs] - self._centroids[class_]) ** 2)\n",
    "        \n",
    "        return _distortion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8bab7950-d679-4c08-8aea-b4d32db72c3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.KMeans at 0x1c8d4402790>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans = KMeans(k=5)\n",
    "kmeans.fit(parametric_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "40637d78-d86b-4a4d-9b16-006f04c3b3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = kmeans.predict(parametric_data)\n",
    "predictions\n",
    "\n",
    "q7_str = array_to_str(predictions)\n",
    "write('q7.txt', q7_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "47cad3f5-a6c2-4002-9e7d-44049076c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids = kmeans.centroids\n",
    "\n",
    "q8_str = array_to_str(centroids)\n",
    "write('q8.txt', q8_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2f564a1d-1337-4a86-8709-4dd5de1e69d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "distortion = kmeans.distortion(parametric_data)\n",
    "\n",
    "q9_str = str(np.around(distortion, 4))\n",
    "write('q9.txt', q9_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b9a9ba-c4fd-4ef0-a591-fd6672c9ce67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
